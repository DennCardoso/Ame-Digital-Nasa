{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.5"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ame Digital - Teste Engenheiro de Dados\n",
    "#\n",
    "# Autor: Dennis Cardoso\n",
    "#\n",
    "# E-mail: dennis.cardoso@outlook.com\n",
    "#\n",
    "# Data: 22 de Dezembro de 2019"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar biblioteca\n",
    "import re\n",
    "from datetime import datetime\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as functions\n",
    "from pyspark import SparkContext, SparkConf, SQLContext"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iniciar spark context\n",
    "conf = SparkConf().setMaster('local[*]')\n",
    "sc = SparkContext().getOrCreate(conf)\n",
    "sqlc =  SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função que retorna String a partir de uma data (ordinal)\n",
    "def str_date(input_date):\n",
    "        try:\n",
    "            return datetime.fromordinal(input_date).strftime('%d/%m/%Y')\n",
    "        except Exception as e:\n",
    "            return '01/01/1900'"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para fazer parse dos dados de entrada\n",
    "def parseLog(data):\n",
    "        ''' Read and parse log data '''\n",
    "        RE_MASK = '(.*) - - \\[(.*):(.*):(.*):(.*)\\] \"(.*)\" ([0-9]*) ([0-9]*|-)'\n",
    "\n",
    "        try:\n",
    "            re_result = re.compile(RE_MASK).match(data)\n",
    "            host = re_result.group(1)\n",
    "            ord_day = datetime.strptime(re_result.group(2), '%d/%b/%Y').toordinal()\n",
    "            req = re_result.group(6)\n",
    "            reply_code = int(re_result.group(7))\n",
    "            \n",
    "            try:\n",
    "                reply_bytes = int(re_result.group(8))\n",
    "            except ValueError as e:\n",
    "                reply_bytes = 0\n",
    "            return host, ord_day, req, reply_code, reply_bytes\n",
    "        \n",
    "        except Exception as e:\n",
    "            return '', -1, '', -1, -1"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaração do Schema de dados a ser utilizado\n",
    "schema = StructType([StructField('host',StringType(), True),StructField('timestamp',IntegerType(), True),StructField('request',StringType(), True),StructField('http_code',IntegerType(), True), StructField('total_bytes',IntegerType(), True)])"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerar RDD com dados dos arquivos\n",
    "rows = sc.textFile('files')\n",
    "\n",
    "# Gerar parse dos dados de Log\n",
    "nasa_parse = rows.map(parseLog)\n",
    "\n",
    "# remover linhas com valores inválidos\n",
    "nasa_rdd = nasa_parse.filter(lambda x: x[1] > -1)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação do Dataframe\n",
    "nasa_df = sqlc.createDataFrame(nasa_rdd, schema)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informativo - Schema do dataframe\n",
    "nasa_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 1 - Número de HOSTs únicos (Utilizando Dataframe e SparkSQL)\n",
    "host_number = nasa_df.select('host').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 2 - Total De error 404 dentro do Periodo (Utilizando Dataframe e SparkSQL)\n",
    "total_404_errors = nasa_df.filter(\"http_code = 404\")\n",
    "total_404_errors_number = total_404_errors.count()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 3 - Quais dias do período especificado tiveram o maior número de erros 404 (Utilizando rdd e reduceByKey).\n",
    "data_404_rdd = nasa_rdd.filter(lambda y: y[3] == 404).map(lambda x: (x[1], 1)) \n",
    "data_404_count = data_404_rdd.reduceByKey(lambda a, b: a+b).sortBy(keyfunc=lambda l: l[1], ascending=False)\n",
    "data_404_list = data_404_count.collect()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 3 - Quais dias do período especificado tiveram o maior número de erros 404 (Utilizando Dataframe e SparkSQL).\n",
    "data_404_list = total_404_errors.groupby('timestamp').agg(functions.count('timestamp').alias('count_error')).orderBy('count_error', ascending=False).collect()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 4 - O total de bytes retornados no período, com uma visão acumulada (Utilizando Dataframe).\n",
    "total_bytes_acc_group = nasa_df.groupby('timestamp').agg(functions.count('total_bytes').alias('sum_bytes'))\n",
    "time = (Window.orderBy('timestamp').rowsBetween(Window.unboundedPreceding, 0))\n",
    "df_cumsum = total_bytes_acc_group.withColumn('cum_sum', functions.sum('sum_bytes').over(time))\n",
    "total_bytes_list = df_w_cumsum.select(['timestamp','cum_sum']).collect()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output para o resultado de Total de Error 404 por dia \n",
    "data_404_final = '\\n'\n",
    "for date_count in data_404_list:\n",
    "    data_404_final += 'Dia %s: %d ocorrências de Erro 404 \\n' % (str_date(int(date_count[0])), date_count[1])"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output para o resultado do Total de Bytes acumulado\n",
    "total_bytes_acc = '\\n'\n",
    "for acc_data in total_bytes_list:\n",
    "   total_bytes_acc += 'Dia %s: %d Bytes \\n' % (str_date(int(acc_data[0])), acc_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gerar mensagem com resultados\n",
    "print('-> 1. Numero de hosts unicos: %s ' % host_number)\n",
    "print('-> 2. Numero total de erros 404: %s ' % total_404_errors_number)\n",
    "print('-> 3. Quais dias do período especificado tiveram o maior número de erros 404 (Lista completa): %s' % data_404_final)\n",
    "print('-> 4. O total de bytes retornados no período, com uma visão acumulada. %s \\n' % total_bytes_acc)"
   ]
  }
 ]
}